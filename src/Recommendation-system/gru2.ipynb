{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "391520b3-2da1-49b4-ad6d-54cda4a321ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 12:57:43.732162: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-01 12:57:44.259077: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-01 12:57:44.454796: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-01 12:57:44.505757: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-01 12:57:44.865251: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-01 12:57:46.281269: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725175668.486117   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725175669.053570   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725175669.053834   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725175669.060725   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725175669.060911   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725175669.060940   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725175669.177721   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725175669.177821   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-01 12:57:49.177831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1725175669.177867   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-01 12:57:49.179090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7372 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import string\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n",
    "import tensorflow.keras.utils as ku\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.6)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da8b5791-5752-42f9-9fe0-a85aaaf6455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdataset = pd.read_csv(\"./dataset/full_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f621a75-e8f5-452f-a1fc-7720f4073938",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rawdataset[:5000]\n",
    "dataset = dataset.drop([\"link\", \"source\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "305f9453-c75b-475f-bbfa-1a088c777a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (5000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[\"1 c. firmly packed brown sugar\", \"1/2 c. eva...</td>\n",
       "      <td>[\"In a heavy 2-quart saucepan, mix brown sugar...</td>\n",
       "      <td>[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[\"1 small jar chipped beef, cut up\", \"4 boned ...</td>\n",
       "      <td>[\"Place chipped beef on bottom of baking dish....</td>\n",
       "      <td>[\"beef\", \"chicken breasts\", \"cream of mushroom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...</td>\n",
       "      <td>[\"In a slow cooker, combine all ingredients. C...</td>\n",
       "      <td>[\"frozen corn\", \"cream cheese\", \"butter\", \"gar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...</td>\n",
       "      <td>[\"Boil and debone chicken.\", \"Put bite size pi...</td>\n",
       "      <td>[\"chicken\", \"chicken gravy\", \"cream of mushroo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>[\"1 c. peanut butter\", \"3/4 c. graham cracker ...</td>\n",
       "      <td>[\"Combine first four ingredients and press in ...</td>\n",
       "      <td>[\"peanut butter\", \"graham cracker crumbs\", \"bu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  title  \\\n",
       "0           0    No-Bake Nut Cookies   \n",
       "1           1  Jewell Ball'S Chicken   \n",
       "2           2            Creamy Corn   \n",
       "3           3          Chicken Funny   \n",
       "4           4   Reeses Cups(Candy)     \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n",
       "1  [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n",
       "2  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n",
       "3  [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...   \n",
       "4  [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n",
       "\n",
       "                                          directions  \\\n",
       "0  [\"In a heavy 2-quart saucepan, mix brown sugar...   \n",
       "1  [\"Place chipped beef on bottom of baking dish....   \n",
       "2  [\"In a slow cooker, combine all ingredients. C...   \n",
       "3  [\"Boil and debone chicken.\", \"Put bite size pi...   \n",
       "4  [\"Combine first four ingredients and press in ...   \n",
       "\n",
       "                                                 NER  \n",
       "0  [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...  \n",
       "1  [\"beef\", \"chicken breasts\", \"cream of mushroom...  \n",
       "2  [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...  \n",
       "3  [\"chicken\", \"chicken gravy\", \"cream of mushroo...  \n",
       "4  [\"peanut butter\", \"graham cracker crumbs\", \"bu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Data shape:\", dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9877aacf-adff-4b71-96b8-a51e7609681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    txt = \"\".join(v for v in txt if v not in string.punctuation.replace(\",\", \"\")).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt\n",
    "\n",
    "NER = [clean_text(x) for x in dataset.NER]\n",
    "ingredients = [clean_text(x) for x in dataset.ingredients]\n",
    "directions = [clean_text(x) for x in dataset.directions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a12b009-701e-4857-935b-3fb39baa959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length: 1120\n",
      "\n",
      "Recipe at index 0:\n",
      " brown sugar, milk, vanilla, nuts, butter, bite size shredded rice biscuits\n"
     ]
    }
   ],
   "source": [
    "finaldataset = []\n",
    "for i in range(len(NER)):\n",
    "    finaldataset.append(NER[i]+\" | \"+directions[i])\n",
    "max_length = 0\n",
    "for i in finaldataset:\n",
    "    max_length = max(max_length, len(i))\n",
    "print(\"max_length:\", max_length)\n",
    "print()\n",
    "finaldataset = NER\n",
    "print(\"Recipe at index 0:\\n\", finaldataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ca5784f-bf58-4b26-9329-3721583fd470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47686"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters='!\"#$%&()*+-./:;<=>?@[\\\\]^_`{}~\\t\\n')\n",
    "\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1    \n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words\n",
    "inp_sequences, total_words = get_sequence_of_tokens(finaldataset)\n",
    "\n",
    "inp_sequences[:10], total_words\n",
    "len(inp_sequences)\n",
    "#tokenizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04816519-d2b2-4f8d-b3c5-a6959c949255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  0,  0, ...,  0,  0, 21],\n",
       "        [ 0,  0,  0, ...,  0, 21,  1],\n",
       "        [ 0,  0,  0, ..., 21,  1,  8],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ..., 13,  8, 14],\n",
       "        [ 0,  0,  0, ...,  8, 14, 19],\n",
       "        [ 0,  0,  0, ..., 14, 19, 77]], dtype=int32),\n",
       " array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 69)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences[:100212])\n",
    "predictors,label,max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82695ee7-287e-4548-a05f-d3af4c98ea3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1725175692.455678   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725175692.455793   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725175692.455808   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725175692.456020   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-01 12:58:12.456034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1725175692.456067   68270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-01 12:58:12.456081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7372 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def create_model(total_words):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Setting early_stopping feature to stop early on getting stagnant\n",
    "    early_stopping = EarlyStopping(\n",
    "    min_delta=0.01, # minimium amount of change to count as an improvement\n",
    "    patience=5, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "    )\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 100))\n",
    "   \n",
    "    # input_dim: Integer. Size of the vocabulary, i.e. maximum integer index + 1.\n",
    "    # output_dim: Integer. Dimension of the dense embedding.\n",
    "    # input_length: Length of input sequences, when it is constant. \n",
    "\n",
    "    # Add Hidden Layer 1 - RNN Layer\n",
    "    model.add(LSTM(200))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(total_words)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d8ec77-b80c-4547-a63b-4b750894858b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 12:58:15.276047: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 40ms/step - loss: 5.5016\n",
      "Epoch 2/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 39ms/step - loss: 4.1626\n",
      "Epoch 3/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 39ms/step - loss: 3.7262\n",
      "Epoch 4/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 38ms/step - loss: 3.4591\n",
      "Epoch 5/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 39ms/step - loss: 3.2596\n",
      "Epoch 6/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 39ms/step - loss: 3.0728\n",
      "Epoch 7/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 40ms/step - loss: 2.9082\n",
      "Epoch 8/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 39ms/step - loss: 2.7585\n",
      "Epoch 9/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 42ms/step - loss: 2.6266\n",
      "Epoch 10/10\n",
      "\u001b[1m1491/1491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 40ms/step - loss: 2.4980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f465835ae90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "948e8179-79ef-4283-bfe5-10464f680fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a08d28af-cdff-4518-b916-9f623a8dcc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dark Sweet Pitted Cherries Pineapple Juice, Lemon Juice, Sugar, Lemon Juice, Lemon Juice, Lemon'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"dark sweet pitted cherries\", 10, model, max_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e9671d6-5624-474f-a64b-576eb93aebd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dark sweet pitted cherries, ginger ale, flavor gelatin, boiling water, almond extract, marshmallows'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NER[10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
